<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Dive into Transformer</title>
  <link rel="stylesheet" href="/style.css">
</head>
<body>
  <header>

    <nav>
      <a href="/">ホーム</a>
      <a href="/papers">論文</a>
      <a href="/ML">機械学習</a>
      <a href="/programming">プログラミング</a>
      <a href="/biology">生物学</a>
    </nav>
  </header>
  
  <main class="container">
    <div class="breadcrumb">
      <a href="/">ホーム</a> > <a href="/papers">論文</a> > AI論文解説: Transformer Architecture
    </div>
    
    <article>
      <h1>Attention is All you need を読む</h1>
      <h2>Transformerモデルとは</h2>
      <p>
        今となってはChat GPTなんかですっかり実用化されてしまっていて
        技術的にはすっかり身近なものになってしまっているTransformerモデルです。そのTransformerモデルが
        最初に提唱されたのは2017年のGoogle研究者による"Attention is All You Needという論文でした（Vaswani et al., 2017）。
        自分たちの論文が世間に、界隈に大きな影響を与えることがわかっていたかのような(というかわかっていたのでしょうが)洒落たタイトルの論文ですね。
        この論文のすごいところは、アイデアとしては元から存在していた"Attention"という考え方を、
        とにかく高速で計算できるようにしました、という単純風なものであるところにあると思っています。
        この論文には難しい数式も全然出てこないし、何となくわかった気になるのは正直全然難しくないんですが、
        それがChat GPTなどの生成AIのようなとんでもない性能のバックグラウンドにあると思うと頭がバグります。また追記します...
      </p>
    </article>
  </main>
  
  <footer>
    <p>&copy; 2024 My Blog. All rights reserved.</p>
  </footer>
</body>
</html>
