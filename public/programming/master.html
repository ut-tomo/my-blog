<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="google-site-verification" content="3iZ0PCFwbOdy1LWlHA3A9nYmzBIZp8Qv12Dw2jHYOEU" />
  <meta name="google-site-verification" content="XvlwfBHUtq90lfXKNDOILZLjLaf1W9QVEWswyW0iwco" />
  <title>Master Theoremとかいうかっこいい定理 - ブログを書いてモチベを上げよう</title>
  <link rel="stylesheet" href="/style.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>
<body>
  <header>
    <h1>ブログを書いてモチベを上げよう</h1>
  </header>
  
  <div class="page-layout">
  <main class="main-content">
    <div class="breadcrumb">
      <a href="/">ホーム</a> > <a href="/programming">機械学習のお勉強</a> > Master Theoremとかいうかっこいい定理
    </div>
    
    <article>
      <h1>Master Theoremとかいうかっこいい定理</h1>
      <p> 2025年6月22日</p>
      
      <h2>概要</h2>
      <p>
        マスター法という定理の知識がどうやら必要になったので、自分で使いこなせる状態を目指してとりあえずまとめてみようと思います。
        どうやらマスター法の説明をしている日本語の文献はあんまりないようで(そんなに調べたわけではないのですが)とりあえず
        手元のアルゴリズムイントロダクションを基本的に参照してまとめていきます。
      </p>
      <h2>マスター定理の主張</h2>
      <p>\( n \in \mathbb{N}, \)上で以下のように定義される漸化式について考える。</p>
        <p>
            \[
            T(n) = aT\left(\frac{n}{b}\right) + f(n)
            \]
            ただし、\( a \geq 0, b > 1, f(n) \)は十分に大きい全ての実数上で定義されている非負の駆動関数(これについては後で書きます)とする。
            この時\( T(n) \)の漸近的な挙動は以下のように分類される。
            <ol class="content-list">
                <li>
                    <p>\(if \quad f(n) = O(n^{\log_ba-\epsilon}) \quad for \, some \quad \epsilon > 0 \implies T(n) = \Theta(n^{\log_ba})\)</p>
                </li>
                <li>
                    <p>\(if \quad f(n) = \Theta(n^{\log_ba}\lg^kn) \quad for \, some \quad k \geq 0 \implies T(n) = \Theta(n^{\log_ba}\lg^{k+1}n)\)</p>
                </li>
                <li>
                    <p>\(if \quad f(n) = \Omega(n^{\log_ba+\epsilon}) \quad for \, some \quad \epsilon > 0 \quad \)<br>
                        \(and \quad af\left(\frac{n}{b}\right) \leq cf(n) \quad for \, some \quad c < 1,\implies T(n) = \Theta(f(n)) \)
                    </p>
            </ol>
        </p>
        <p>
            これだけみるとうーんと唸るしかないですよね。ちなみに明記していませんでしたが\(n\)は基本的に十分に大きな数
            について考えています。小さいnについて考えても計算量の見積もりとなるとあまり意味がないので。
        </p>

        <h2>漸近記法</h2>
        <p>
        上で登場した\( O, \Theta, \Omega \)は漸近記法と呼ばれるもので、計算量の見積もりに使われるものですが、正直ビッグオー記法以外は僕は馴染みがなかったので
        \( \Theta, \Omega \)について触れておきたいです。</p>
        <div style="margin: 20px;"></div>
        <h3>\(\Omega\)記法</h3>
        <p>
            \[
            f(n) \in \Omega(g(n)) \Leftrightarrow \exists c > 0, n_0 \in \mathbb{N} \quad s.t. \quad f(n) \geq cg(n) \geq 0 \quad for \, all \quad n \geq n_0
            \]
        </p>
        <h3>\(\Theta \)記法</h3>
        <p>
            \[
            f(n) \in \Theta(g(n)) \Leftrightarrow \exists c_1, c_2 > 0, n_0 \in \mathbb{N} \quad s.t. \quad c_1g(n) \leq f(n) \leq c_2g(n) \quad for \, all \quad n \geq n_0
            \]
        </p>
        <p>
            ビッグオー記法は計算量の見積もりによくみる記法で、漸近的上界を与えるものです。つまり、
            十分に大きな\( n \)に対して、\( f(n) \)は\( g(n) \)の定数倍以下であることを示します。
            一方で、\(\Omega\)記法は漸近的下界を与えるもので、十分に大きな\( n \)に対して、\( f(n) \)は\( g(n) \)の定数倍以上であることを示します。
            \(\Theta\)記法は、アルゴリズムイントロダクションでは漸近的に"タイトな"限界のために用いると書かれています。
            つまりは、十分に大きな\( n \)に対して、\( f(n) \)は\( g(n) \)の定数倍以上かつ以下であることを示しており、
            任意に2つの関数\(f(n)\)と\(g(n)\)を選んだ際に\(f(n) = \Theta(g(n))\)である必要十分条件は
            \(f(n) = O(g(n))\)かつ\(f(n) = \Omega(g(n))\)であることになります。
        </p>
        <p>
            これらの記法がわかると、なんとなくマスター定理の主張せんとするところが見えてきます。
            最終的には漸化式に対して漸近解を与えたいというのがMaster定理な訳ですが、なんらかの場合分けの基準があって、
            漸近的な挙動を分類しているということぐらいはこの時点で読み取れる気がします。
            
        </p>
        <h2>まずはもう一度漸化式をよくみる</h2>
        <p>
            さて、マスター定理の漸化式をもう一度よく見てみましょう。
            \[
            T(n) = aT\left(\frac{n}{b}\right) + f(n)
            \]
            この式をが見積もろうとしているものは、サイズ\(n\)の問題をサイズ\(n/b\)を持つ\(a\)個のサブ問題
            に分割することによるアルゴリズムの計算コストです。つまりこのアルゴリズムは
            \(a\)個の部分問題をそれぞれ\(T(n/b)\)の時間で再帰的に解くものであり、
            \(f(n)\)は再帰の外で発生する計算時間、つまり問題の分割や結合に要するコストを表しているものとなります。
            そして、部分問題を解くのにかかるコストと再帰以外のコストを天秤にかけて、
            支配的な方のコストが全体の計算コストを決めるというのが基本的なアイデアです。
            ちなみに、\(f(n)\)が駆動関数と呼ばれるのはこの部分がアルゴリズム全体のコストを決めうるから、ということだそうですが、
            それなら両方ともそうじゃないか。
        </p>
        <h2>主張の気持ちだけでも理解する</h2>
        <p>
            マスター定理では、駆動関数が\(n^{\log_ba}\)より支配的か否かによる場合わけがまずなされています。
            ちなみにこの\(n^{\log_ba}\)は分水界関数と呼ぶようです。こいつがまずどこから来たのかを考えたいですね。
        </p>
        <p>
            まず、再帰呼び出し1回あたり\(a\)個の部分問題が生成され、それぞれのサイズは再帰呼び出しが\(i\)回目の時は
            \(\frac{n}{b^i}\)となります。この時再帰呼び出しは問題サイズが定数になるまで続くと考えれば
            再帰の深さは\(\approx \log_b n\)となります。
        </p>
        <p>
            つまり再帰的に呼び出すことによるノード数は
            \[
            \sum_{i=0}^{\log_b n} a^i \approx \frac{a^{\log_b n} - 1}{a - 1} \approx a^{\log_bn}
            \]
            \[
            a^{\log_bn} = e^{\log a \frac{\log n}{\log b}} = n^{\log_b a}
            \]
        </p>
        <p>
            となります。ノード数と書いたのは、再帰的に呼び出すことにより1つの親ノードから\(a\)個の子ノードが生成されるような
            木構造を想像するとわかりやすいと思ったからです。というわけで局所的な処理を一切考えなければ再帰的な
            呼び出しによる計算コストは\(n^{\log_b a}\)となることがわかり、分水界関数と呼んでいるものが得られたことになります。
            これくらいのことがわかればマスター方を覚えることくらいはできそうなので、問題を解く時に使えと言われればできそうではありますが、
            流石にまだモヤモヤする部分が残り過ぎているのでもう少し丁寧にそれぞれのケースについて考えます。
        </p>
        <h2>Case 1</h2>
        <p>
            Case 1での要求は、「<span class="red-underline">分水界関数が駆動関数よりも"多項式的に"速く漸近的に増加してほしい</span>」というものです。
            つまり、ただ分水界関数の方が速けりゃいいというわけではないのです。
            それは以下のことが保証されていてほしいからになります。
            \[
            \frac{f(n)}{n^{\log_b a}} \to 0 \quad as \quad n \to \infty
            \]
            要は\(n\)が十分に大きくなった時に駆動関数の寄与は無視できますよという状況が望ましいということで、これは
            \(f(n) = O(n^{\log_b a - \epsilon})\)であれば
            \[
            \frac{f(n)}{n^{\log_b a}} = O\left(\frac{1}{n^{\epsilon}}\right) \to 0 \quad as \quad n \to \infty
            \]
            となるので多項式的に遅ければ満たしてくれることはわかります。
            多項式的には速くない(つまり, 最大でもlog関数程度の差しかないなど)であればこの点が保証されず困るので"for some \(\epsilon > 0\)"という条件がついています。
            数学的にバッチリしていないのは目を瞑ってください。
        </p>
        <h2>Case 2</h2>
        <p>
            Case 2はこれまでの説明を踏まえても割となんじゃこりゃという見た目をしています。
            コンテキストとしては分水界関数と駆動関数が同じくらいのオーダーで増加している
            場合を考えているんだろうという推測はつきますが。同じくらいと言っていますが、
            もう少しよくみると
            \(f(n) = \Theta(n^{\log_b a} \lg^k n)\)
            と言っているので駆動関数の方がやや速い状況を考えています。そしてここで、
            Case 1の説明の際に省かれた、「分水界関数が駆動関数よりも速いが多項式オーダーの差はない」という状況は
            この定理では考慮されていないことに気づきます。
        </p>
        <p>
            では改めてCase 2を考えるわけですが、これは先ほど分水界関数を導いてきた時と同じように
            木構造を考えるとわかりやすいでしょうか。
        </p>
        <div style="margin: 20px;"></div>
        <p>
            レベル\(i\)のノード数は\(a^i\)であり、各ノードの計算コストは以下のようになります。
            \[
            T_i = a^i \cdot f\left(\frac{n}{b^i}\right) = a^i \cdot \Theta\left(\left(\frac{n}{b^i}\right)^{\log_b a} \lg^k\left(\frac{n}{b^i}\right)\right)
            \]
            ここで、\(a^i = b^{i\log_ba}\)ですから、
            \[
            T_i = \Theta\left(n^{\log_b a} \cdot \lg^k\left(\frac{n}{b^i}\right)\right) = \Theta\left(n^{\log_b a} \cdot (\lg n - i \lg b)^k \right)
            \]
            となって、木の深さ\(\log_b n\)から全体の計算コストは
            \[
            T(n) = \sum_{i=0}^{\log_b n} T_i = \sum_{i=0}^{\log_b n} \Theta\left(n^{\log_b a} \cdot (\lg n - i \lg b)^k \right)
            \]
            つまり、各階層の計算コストは平均的に\(\Theta(n^{\log_b a} \cdot (\lg n - C)^k) = \Theta(n^{\log_b a} \cdot \lg^k n)\)となり(C: const.)、
            木の深さ\(\log_b n\)にわたってこの計算コストが繰り返されるので、最終的な計算コストは
            \[
            T(n) = \Theta(n^{\log_b a} \cdot \lg^{k+1} n)
            \]
            となるという形です。
        </p>
        <h2>Case 3</h2>
        <p>
            Case 3は分水界関数が駆動関数よりも遅い場合を考えています。
            つまり、分水界関数が駆動関数よりも速く漸近的に増加していることを要求しています。
            ここでの要求は、\(f(n) = \Omega(n^{\log_b a + \epsilon})\) であることです。
            これは、分水界関数が駆動関数よりも速く増加していることを意味します。
            つまり、再帰呼び出しによるコストが全体の計算コストに対して無視できるほど小さいことを意味します。
            考え方はCase 1と同じものが反映されているので、Case 2よりは受け入れやすいと思います。

            このとき注意しなければならないのは、「駆動関数が支配的である」と結論づけるためには、
            単に漸近的に分水界関数より大きいというだけでは不十分だということです。
            たとえば、駆動関数が \(n^{\log_b a + \epsilon}\) のように増加していたとしても、
            それが局所的に不規則だったり、再帰の中でスケーリングされたときに再び大きくなるような挙動を持っていると、
            再帰呼び出しのコスト \(aT(n/b)\) が無視できなくなる可能性があります。

            このため、Case 3 ではさらに「正則条件（regularity condition）」という技術的な条件を課しています。
            これは次のように表されます：

            \[
            \exists c < 1,\ \exists n_0\ \text{such that} \quad a f(n/b) \leq c f(n) \quad \text{for all } n \geq n_0
            \]

            この条件の意味は、駆動関数の成長が十分に速いために、再帰で現れるスケーリング済みの駆動コスト \(f(n/b)\) が
            本体の \(f(n)\) に比べて明らかに小さくなるということです。
            その結果として、再帰呼び出し全体のコスト \(aT(n/b)\) は、最上位の \(f(n)\) によって吸収される程度に小さくなっていくと考えられます。

            再帰木の構造で見ると、上のレベル（ルート付近）では \(f(n)\) が大きく、
            下層にいくにつれて再帰部分が指数的に減衰していくことがこの条件によって保証されます。
            これにより、再帰部分の合計が有限で抑えられ、全体の計算量は \(f(n)\) によって支配されると安心して言えるようになるのです。

            したがって、正則条件は Case 3 の主張が真であることを保証するための安全装置であり、
            駆動関数の支配が安定して継続することを担保する役割を持っています。
            これがあるからこそ、私たちは \(T(n) = \Theta(f(n))\) と結論づけることができるのです。
        </p>

        <div style="margin: 20px;"></div>
        <hr>
        <div style="margin: 20px;"></div>
        <h2>まとめ</h2>
        <p>
            全てのCaseのお気持ちはなんとなくわかったということで、改めてそれぞれを見比べて終わろうと思います。適用例はまた別記事かな。
            Master 定理を見ていく上でちょくちょく木構造の話を登場させましたが、それは
            再帰木としての見方はこの定理の直感的な理解を助けるからです。

            Case 1 では、駆動関数 \( f(n) \) が分水界関数 \( n^{\log_b a} \) より多項式的に小さいと仮定しています。
            このとき再帰木の各レベルでのコストは、深くなるほど増加し、特に最下層（葉）の合計コストが全体を支配するようになります。
            したがって、全体の計算量は葉のレベルのコスト、すなわち \( \Theta(n^{\log_b a}) \) になります。

            Case 2 では、駆動関数が分水界関数と同じオーダー（例えば \( f(n) = \Theta(n^{\log_b a} \log^k n) \)）であるときの振る舞いを扱います。
            このとき再帰木の各レベルのコストは、すべてほぼ同じオーダーになります。
            木の高さは \( \log_b n \) なので、全体としては \( \log n \) レベルぶんのコストが加算され、結果として
            \[
            T(n) = \Theta(n^{\log_b a} \log^{k+1} n)
            \]
            のように \( \log^{k+1} n \) が現れます。

            Case 3 では、駆動関数が分水界関数よりも多項式的に大きいと仮定します。
            ここでは再帰木の根（最上層）のコストが最も支配的であり、下層へ行くほど再帰による影響は急速に減衰していきます。
            この「上から下へ指数的に弱まっていく」構造が成立するためには、正則条件（regularity condition）：
            \[
            \exists c < 1,\ \exists n_0\ \text{such that } a f(n/b) \leq c f(n)
            \]
            が必要になります。
            この条件により、再帰呼び出しが駆動関数に吸収され、全体として
            \[
            T(n) = \Theta(f(n))
            \]
            と結論づけられるのです。

            このように、再帰木を通して各Caseの支配的なレベル（葉、中間、根）のコストをそれぞれ天秤にかけていると思えば、
            式を見て面食らうということにはならないのではないのでしょうか。
        </p>
        <div style="margin: 20px;"></div>
        <p>
            結構個人的にはかなりマスター定理と仲良くなれそうな気がしてきました。実際に適用していくのはまた今度以降の記事になります。
        </p>
    </article>
  </main>
  
  <aside class="sidebar">
    <h3>カテゴリ</h3>
    <ul>
      <li><a href="/papers" >論文記録</a></li>
      <li><a href="/ML">機械学習のお勉強</a></li>
      <li><a href="/programming" class="active">その他プログラミング / 情報科学</a></li>
      <li><a href="/bio\logy">その他生物学関連</a></li>
    </ul>
  </aside>
</div>

<button class="mobile-menu-btn" onclick="toggleSidebar()">
  <span>☰</span>
</button>

<div class="sidebar-overlay" onclick="closeSidebar()"></div>
  
  <footer>
    <p>&copy; 2025 ブログを書いてモチベを上げよう. All rights reserved.</p>
  </footer>

  <script>
function toggleSidebar() {
  const sidebar = document.querySelector('.sidebar');
  const overlay = document.querySelector('.sidebar-overlay');
  
  sidebar.classList.toggle('active');
  overlay.classList.toggle('active');
}

function closeSidebar() {
  const sidebar = document.querySelector('.sidebar');
  const overlay = document.querySelector('.sidebar-overlay');
  
  sidebar.classList.remove('active');
  overlay.classList.remove('active');
}
function copyCode(button) {
  const codeBlock = button.closest('.code-block');
  const codeContent = codeBlock.querySelector('.code-content code');
  const text = codeContent.textContent;
  
  navigator.clipboard.writeText(text).then(() => {
    const originalText = button.textContent;
    button.textContent = 'Copied!';
    button.classList.add('copied');
    
    setTimeout(() => {
      button.textContent = originalText;
      button.classList.remove('copied');
    }, 2000);
  }).catch(err => {
    console.error('コピーに失敗しました:', err);
    // フォールバック: 古いブラウザ対応
    const textArea = document.createElement('textarea');
    textArea.value = text;
    document.body.appendChild(textArea);
    textArea.select();
    document.execCommand('copy');
    document.body.removeChild(textArea);
    
    const originalText = button.textContent;
    button.textContent = 'Copied!';
    button.classList.add('copied');
    
    setTimeout(() => {
      button.textContent = originalText;
      button.classList.remove('copied');
    }, 2000);
  });
}
</script>
</body>
</html>
